{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3204ec29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44b0d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx      class                                       conversation\n",
       "0    0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...\n",
       "1    1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...\n",
       "2    2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...\n",
       "3    3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...\n",
       "4    4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath_train = os.getenv('HOME')+'/aiffel/dktc/data/train.csv'\n",
    "\n",
    "train = pd.read_csv(filepath_train)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f748672e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3950"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67cc9145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx             0\n",
       "class           0\n",
       "conversation    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa47d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          협박 대화\n",
       "2      기타 괴롭힘 대화\n",
       "3          갈취 대화\n",
       "5    직장 내 괴롭힘 대화\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['class'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b946f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 클렌징 함수\n",
    "def clean_text(text):\n",
    "    # 불필요한 특수 문자, 숫자 제거 (한글, 영문, 공백 제외)\n",
    "    text = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    return text\n",
    "\n",
    "train['conversation'] = train['conversation'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22cdaa0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ce8635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /aiffel/aiffel/dktc/.cache/kobert_v1.zip\n",
      "using cached model. /aiffel/aiffel/dktc/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#bert 모델, vocab 불러오기\n",
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7545c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[(train['class'] == \"협박 대화\"), 'label'] = 0  # 협박 대화 => 0\n",
    "train.loc[(train['class'] == \"갈취 대화\"), 'label'] = 1  # 갈취 대화 => 1\n",
    "train.loc[(train['class'] == \"직장 내 괴롭힘 대화\"), 'label'] = 2  # 직장 내 괴롭힘 대화 => 2\n",
    "train.loc[(train['class'] == \"기타 괴롭힘 대화\"), 'label'] = 3  # 기타 괴롭힘 대화 => 3\n",
    "train.loc[(train['class'] == \"일반 대화\"), 'label'] = 4  # 일반 대화 => 4\n",
    "\n",
    "data_list = []\n",
    "for content, label in zip(train['conversation'], train['label'])  :\n",
    "    temp = []\n",
    "    temp.append(content)\n",
    "    temp.append(str(int(label)))\n",
    "\n",
    "    data_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2110272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns = 'idx', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "313f539b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['지금 너 스스로를 죽여달라고 애원하는 것인가  아닙니다 죄송합니다  죽을 거면 혼자 죽지 우리까지 사건에 휘말리게 해 진짜 죽여버리고 싶게  정말 잘못했습니다  너가 선택해 너가 죽을래 네 가족을 죽여줄까  죄송합니다 정말 잘못했습니다  너에게는 선택권이 없어 선택 못한다면 너와 네 가족까지 모조리 죽여버릴거야  선택 못하겠습니다 한번만 도와주세요  그냥 다 죽여버려야겠군 이의 없지  제발 도와주세요',\n",
       " '0']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d477eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = train_test_split(data_list, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "753999e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        \n",
    "        # 레이블이 없는 경우를 처리\n",
    "        if label_idx is not None:\n",
    "            self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "        else:\n",
    "            self.labels = None\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.labels is not None:\n",
    "            return self.sentences[i] + (self.labels[i], )\n",
    "        else:\n",
    "            return self.sentences[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4af9aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 130\n",
    "batch_size = 32\n",
    "warmup_ratio = 0.2\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae6c62c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /aiffel/aiffel/dktc/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "#BERTDataset 클래스 이용, TensorDataset으로 만들어주기\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2353103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# 배치 및 데이터로더 설정 (num_workers 최적화)\n",
    "# num_workers는 시스템에 맞춰 적절한 값을 설정 (예: CPU 코어 수에 맞춰 4나 8 정도로 설정)\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=8, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32907d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size=768,\n",
    "                 num_classes=5,\n",
    "                 dr_rate=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "    def forward(self, token_ids, segment_ids):\n",
    "        # attention mask는 token_ids에서 패딩(0)이 아닌 부분을 1로 설정\n",
    "        attention_mask = (token_ids != 0).float()\n",
    "        \n",
    "        # BERT 모델에서 pooler 출력 사용\n",
    "        _, pooler = self.bert(input_ids=token_ids, token_type_ids=segment_ids.long(), attention_mask=attention_mask.float().to(token_ids.device))\n",
    "        \n",
    "        # 드롭아웃 적용\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        \n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47379488",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b821bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb33713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42c1aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# 성능 지표 계산 함수\n",
    "def calc_metrics(X, Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    pred_labels = max_indices.cpu().numpy()\n",
    "    true_labels = Y.cpu().numpy()\n",
    "    \n",
    "    accuracy = (pred_labels == true_labels).sum() / len(true_labels)\n",
    "    f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
    "    precision = precision_score(true_labels, pred_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, pred_labels, average='weighted')\n",
    "    \n",
    "    return accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5734d474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_833/2530363836.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, _, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95c5f94dafa4a8aac8431b17bcdaa1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 1: Loss 1.6723501682281494, Accuracy 0.25, F1 0.1846153846153846, Precision 0.1875, Recall 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Accuracy 0.5083122895622896, F1 0.49024323397438996, Precision 0.5468266290820959, Recall 0.5083122895622896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_833/2530363836.py:37: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, _, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e4ced8dee74a4b9a8ad96a5dd9b953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Accuracy 0.7807954545454545, F1 0.7802289581237511, Precision 0.8244404935342434, Recall 0.7807954545454545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_833/2530363836.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, _, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd084bee4e8444399d5dabd1af0c81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 1: Loss 0.5941647887229919, Accuracy 0.84375, F1 0.847885101010101, Precision 0.8797348484848485, Recall 0.84375\n",
      "Epoch 2: Train Accuracy 0.829124579124579, F1 0.8287978409494354, Precision 0.8578396047633459, Recall 0.829124579124579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_833/2530363836.py:37: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, _, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b471c3b2184b99bdb8d21c87ca6f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validation Accuracy 0.8695454545454545, F1 0.8679291340708641, Precision 0.8880900419025417, Recall 0.8695454545454545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_833/2530363836.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, _, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ade3c1494747c98a05a73ed3929744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 1: Loss 0.20815126597881317, Accuracy 0.9375, F1 0.9302083333333333, Precision 0.9488636363636364, Recall 0.9375\n",
      "Epoch 3: Train Accuracy 0.9029882154882154, F1 0.9021810088746306, Precision 0.9155529459901303, Recall 0.9029882154882154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_833/2530363836.py:37: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, _, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6a99199e634adbafd9e1413d576606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Validation Accuracy 0.8727272727272727, F1 0.8729235794665641, Precision 0.8897269674769674, Recall 0.8727272727272727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_833/2530363836.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, _, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba826e210ff4f5ba86f966ea62315fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 1: Loss 0.1419556438922882, Accuracy 0.96875, F1 0.969326923076923, Precision 0.9732142857142857, Recall 0.96875\n",
      "Epoch 4: Train Accuracy 0.9531776094276094, F1 0.9532035098098544, Precision 0.9596055369177213, Recall 0.9531776094276094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_833/2530363836.py:37: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, _, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8aedc41b8d4160a4a5540629c18129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Validation Accuracy 0.8757954545454545, F1 0.87516361033855, Precision 0.8877358405483406, Recall 0.8757954545454545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_833/2530363836.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, _, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d5757ad7244c888d6f49a49af367ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 1: Loss 0.08512581884860992, Accuracy 0.9375, F1 0.9375, Precision 0.9375, Recall 0.9375\n",
      "Epoch 5: Train Accuracy 0.9791666666666666, F1 0.9790149231653622, Precision 0.981278775762677, Recall 0.9791666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_833/2530363836.py:37: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, _, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4652b5cb4bd044ef84386168bdf616b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Validation Accuracy 0.8789772727272727, F1 0.8786155846184492, Precision 0.890780629093129, Recall 0.8789772727272727\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    # 각 에포크 시작 시 성능 지표 초기화\n",
    "    train_acc = 0.0\n",
    "    train_f1, train_precision, train_recall = 0.0, 0.0, 0.0  # 성능 지표 초기화\n",
    "    test_acc, val_f1, val_precision, val_recall = 0.0, 0.0, 0.0, 0.0  # Validation 성능 지표 초기화\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_id, (token_ids, _, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        label = label.long().to(device)\n",
    "        \n",
    "        out = model(token_ids, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        \n",
    "        # 성능 지표 계산\n",
    "        batch_acc, batch_f1, batch_precision, batch_recall = calc_metrics(out, label)\n",
    "        train_acc += batch_acc\n",
    "        train_f1 += batch_f1\n",
    "        train_precision += batch_precision\n",
    "        train_recall += batch_recall\n",
    "        \n",
    "        if batch_id % log_interval == 0:\n",
    "            print(f\"Epoch {e+1} Batch {batch_id+1}: Loss {loss.data.cpu().numpy()}, Accuracy {train_acc/(batch_id+1)}, F1 {train_f1/(batch_id+1)}, Precision {train_precision/(batch_id+1)}, Recall {train_recall/(batch_id+1)}\")\n",
    "    \n",
    "    print(f\"Epoch {e+1}: Train Accuracy {train_acc/len(train_dataloader)}, F1 {train_f1/len(train_dataloader)}, Precision {train_precision/len(train_dataloader)}, Recall {train_recall/len(train_dataloader)}\")\n",
    "    \n",
    "    # Validation 성능 계산\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_id, (token_ids, _, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "            token_ids = token_ids.long().to(device)\n",
    "            segment_ids = segment_ids.long().to(device)\n",
    "            label = label.long().to(device)\n",
    "            \n",
    "            out = model(token_ids, segment_ids)\n",
    "            batch_acc, batch_f1, batch_precision, batch_recall = calc_metrics(out, label)\n",
    "            test_acc += batch_acc\n",
    "            val_f1 += batch_f1\n",
    "            val_precision += batch_precision\n",
    "            val_recall += batch_recall\n",
    "        \n",
    "        print(f\"Epoch {e+1}: Validation Accuracy {test_acc/len(test_dataloader)}, F1 {val_f1/len(test_dataloader)}, Precision {val_precision/len(test_dataloader)}, Recall {val_recall/len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d31b0892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_833/2115962489.py:39: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6c5a421fb84474a228afe387530096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to mysubmission.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# test.json 파일 경로 설정\n",
    "filepath_test = os.getenv('HOME')+'/aiffel/dktc/data/test.json'\n",
    "\n",
    "# test.json 파일을 DataFrame으로 읽기 (pandas를 사용하는 경우)\n",
    "test_data = pd.read_json(filepath_test)\n",
    "\n",
    "# 각 열에 있는 'text' 데이터를 추출하여 하나의 리스트로 만듭니다.\n",
    "test_list = []\n",
    "\n",
    "for column in test_data.columns:\n",
    "    conversation = test_data[column]['text']\n",
    "    test_list.append([conversation])  # 각 대화를 리스트에 추가\n",
    "\n",
    "# 텍스트 클렌징 함수 (train에서 사용한 것과 동일하게 적용)\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    return text\n",
    "\n",
    "# 전처리 적용\n",
    "test_list = [[clean_text(conversation[0])] for conversation in test_list]\n",
    "\n",
    "# 토큰화 및 데이터셋 변환 (BERTDataset 클래스 및 토크나이저는 이미 정의되어 있다고 가정)\n",
    "data_test = BERTDataset(test_list, 0, None, tok, max_len, True, False)\n",
    "\n",
    "# 테스트 데이터 로더 생성\n",
    "test_dataloader = DataLoader(data_test, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "# 모델 예측\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_id, (token_ids, valid_length, segment_ids) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        \n",
    "        # 모델 예측\n",
    "        out = model(token_ids, segment_ids)\n",
    "        pred = torch.argmax(out, dim=1).cpu().numpy()  # 가장 높은 확률의 클래스를 예측\n",
    "        predictions.extend(pred)\n",
    "\n",
    "# 숫자 레이블을 클래스명으로 변환하는 매핑\n",
    "label_mapping = {\n",
    "    0: \"0\",\n",
    "    1: \"1\",\n",
    "    2: \"2\",\n",
    "    3: \"3\",\n",
    "    4: \"4\"\n",
    "}\n",
    "\n",
    "# 예측된 숫자 레이블을 클래스명으로 변환\n",
    "predicted_classes = [label_mapping[pred] for pred in predictions]\n",
    "\n",
    "# 예측 결과를 DataFrame으로 변환\n",
    "submission = pd.DataFrame({\n",
    "    'idx': test_data.columns,  # 각 대화에 해당하는 열 이름 (예: 't_000', 't_001' 등)\n",
    "    'target': predicted_classes  # 예측된 클래스명\n",
    "})\n",
    "\n",
    "# 제출 파일로 저장\n",
    "submission.to_csv('./mysubmission.csv', index=False)\n",
    "print(\"Results saved to mysubmission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95dab8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
